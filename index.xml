<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data Science Portfolio on Serge ADOMAYAKPO</title>
    <link>https://sergioado.github.io/portfolio/</link>
    <description>Recent content in Data Science Portfolio on Serge ADOMAYAKPO</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 02 Mar 2017 12:00:00 -0500</lastBuildDate><atom:link href="https://sergioado.github.io/portfolio/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Contact</title>
      <link>https://sergioado.github.io/portfolio/contact/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sergioado.github.io/portfolio/contact/</guid>
      <description>Vous pouvez me joindre sur les platformes suivantes:
   Platforme Lien     Gmail sergeadomayakpo@gmail.com   LinkedIn https://www.linkedin.com/in/serge-adomayakpo-94664919/   GitHub https://github.com/SergioAdo    </description>
    </item>
    
    <item>
      <title>Projet 1: Classifieur de races de chiens (Deep Learning)</title>
      <link>https://sergioado.github.io/portfolio/post/project1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sergioado.github.io/portfolio/post/project1/</guid>
      <description>J&amp;rsquo;ai cree un outil de detection de race de chien avec un taux d&amp;rsquo;erreur d&amp;rsquo;environ 14% Le langage Python a ete utilise pour la creation du modele sous fastai Le dataset des images de chiens provient de la platforme Kaggle Transfer Learning utilise avec comme architecture ResNet34 L&#39; API a ete fait avec Render    Lien du repo GitHub</description>
    </item>
    
    <item>
      <title>Projet 2: Chicago Crime Rate (Time Series)</title>
      <link>https://sergioado.github.io/portfolio/post/project2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sergioado.github.io/portfolio/post/project2/</guid>
      <description>Prediction du nombre de crime a Chicago L&amp;rsquo;analyse s&amp;rsquo;est faite en recuperant les chiffres de 2005 a 2017 Le dataset peut etre telecharge sur l&amp;rsquo;adresse suivante La prediction a pu se faire grace a l&amp;rsquo;outil Prophet cree par Facebook      Lien du repo GitHub</description>
    </item>
    
    <item>
      <title>Projet 3: WWE (Data Analysis/Sport Analytics)</title>
      <link>https://sergioado.github.io/portfolio/post/project3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sergioado.github.io/portfolio/post/project3/</guid>
      <description>WWE (World Wrestling Entertainmnent) is the largest professional wrestling promotion in the world. It has promoted some of the most successful wrestlers and storylines, and featured some of the most iconic and significant matches and moments in the history of sports entertainment. WWE currently airs several high-profile programs such as Raw and SmackDown in more than 150 countries, hosts 12 pay-per-view events a year including WrestleMania, and holds approximately 320 live events a year throughout the world.</description>
    </item>
    
    <item>
      <title>Projet 4: Prix de voiture (Machine Learning -Regression-)</title>
      <link>https://sergioado.github.io/portfolio/post/project4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sergioado.github.io/portfolio/post/project4/</guid>
      <description>Plusieurs modeles construits grace a la librairie Pycaret L&amp;rsquo;algorithme Random Forest est celui qui a ete retenu au final RMSE : 2176 R2 : 0.88 Web app fait avec Streamlit    Link to GitHub Repo</description>
    </item>
    
    <item>
      <title>Projet 5: Attrition des employes (Machine Learning -Classification-)</title>
      <link>https://sergioado.github.io/portfolio/post/project5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sergioado.github.io/portfolio/post/project5/</guid>
      <description>Modele de classification binaire construit a partir d&amp;rsquo;un dataset provenant de Pycaret Modele cree sur la base de 14249 personnes (10863 restees et 3386 parties) Accuracy : 0.9872 F1 - score: 0.9727 Application creee sur Streamlit    Lien du repo GitHub</description>
    </item>
    
    <item>
      <title>Projet 6: Maladies cardiaques (Machine Learning &amp; Deep Learning -Classification-) </title>
      <link>https://sergioado.github.io/portfolio/post/project6/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sergioado.github.io/portfolio/post/project6/</guid>
      <description>Modeles crees manuellement avec scikit-learn, tensorflow et automatiquement avec pycaret Application developpee sous Flask et deployee sur Heroku Dataset d&amp;rsquo;environ 1200 patients AUC = 0.953 F1 - score = 0.923 Accuracy = 0.913    Lien du repo GitHub</description>
    </item>
    
    <item>
      <title>Projet 7: Boxe ( Data Analysis/Sport Analytics)</title>
      <link>https://sergioado.github.io/portfolio/post/project7/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sergioado.github.io/portfolio/post/project7/</guid>
      <description>Voici ici quelques chiffres et records des meilleurs boxeurs de l&amp;rsquo;histoire de la boxe.
Tous les graphiques et dashboard sont visibles dans le fichier pdf sur le repo
  Lien du repo GitHub</description>
    </item>
    
    <item>
      <title>Projet 8: Championnat Allemand de Football (Data Analysis/ Sport Analytics) </title>
      <link>https://sergioado.github.io/portfolio/post/project8/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sergioado.github.io/portfolio/post/project8/</guid>
      <description>Ce projet est une analyse explorative de donnees du championnat allemand de football depuis 1963. Les donnees sont issues de 57 pages de wikipedia. Chaque page correspondant au classement final de chaque saison. J&amp;rsquo;ai pu extraire ces donnees grace a un outil open source de web scraping: ParseHub.
    Lien du repo GitHub</description>
    </item>
    
    <item>
      <title>Projet 9: BBC news (NLP) </title>
      <link>https://sergioado.github.io/portfolio/post/project9/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sergioado.github.io/portfolio/post/project9/</guid>
      <description>Je me suis inspire d&amp;rsquo;un tutoriel sur la classification de vrais mails et spams avec Pytorch, pour realiser ce projet sur des articles de presse de la BBC.
5 categories a detecter:
0: Business 1: Entertainment 2: Politics
3: Sport 4: Tech
  Lien du repo GitHub</description>
    </item>
    
  </channel>
</rss>
